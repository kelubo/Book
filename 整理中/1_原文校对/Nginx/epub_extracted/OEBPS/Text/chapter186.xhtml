<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>未知</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link rel="stylesheet" type="text/css" href="../../stylesheet.css"/>
<link rel="stylesheet" type="text/css" href="../../page_styles.css"/>
</head>
  <body class="calibre">
  <h3 class="p" id="sigil_toc_id_200">10.4.5　Prometheus监控告警</h3>

  <p class="ziti3">Prometheus监控告警是通过Alertmanager组件实现的。Alertmanager提供标准的RESTful api接口接收警报信息，其将告警信息按照规则重定向给接收者，接收者可以是邮箱、webhook和微信等。Alertmanager会对已发送的告警进行智能记录并做延时、去重等处理，从而有效避免告警风暴的产生。</p>

  <p class="ziti3">（1）Prometheus监控告警处理流程如下：</p>

  <p class="ziti4">·Prometheus Server根据配置参数evaluation_interval的时间间隔按照告警规则进行计算。</p>

  <p class="ziti4">·当不满足expr设定计算规则的阈值时，该告警规则被置为inactive状态。</p>

  <p class="ziti4">·当满足expr设定计算规则的阈值并小于for设定的持续时间时，该告警规则被置为pending状态。</p>

  <p class="ziti4">·当满足expr设定计算规则的阈值并大于for设定的持续时间时，该告警规则被置为firing状态，并发送告警信息给Alertmanager处理。</p>

  <p class="ziti4">·Alertmanager接收到告警信息后，根据labels进行路由分拣，告警信息会根据group_by配置进行分组，如果分组不存在，则新建分组。</p>

  <p class="ziti4">·新创建的分组将等待group_wait指定的时间（等待时如收到同一分组的告警信息，将其进行合并），然后发送通知。</p>

  <p class="ziti4">·已有分组时将等待group_interval指定的时间，当上次发送通知到现在的间隔大于repeat_interval或者分组有更新时会发送通知。</p>

  <p class="ziti3">（2）告警规则格式</p>
  <hr class="calibre6"/>
  <pre class="ziti5">ALERT &lt;alert name&gt;                # 告警标识符，可以不唯一
  IF &lt;expression&gt;             # 触发告警阈值规则
  [ FOR &lt;duration&gt; ]          # 触发告警通知的持续时间
  [ LABELS &lt;label set&gt; ]      # 分组标签，用以Alertmanager进行分拣路由
  [ ANNOTATIONS &lt;label set&gt; ] # 告警描述信息
</pre>
  <hr class="calibre6"/>

  <p class="ziti3">（3）Prometheus Server配置告警规则格式</p>
  <hr class="calibre6"/>
  <pre class="ziti5">cat&gt;prometheus/prometheus/nginx.rules&lt;&lt;EOF
groups:
- name: NginxAlert # 规则组名称
  rules:
    - alert: ResponseTimeAlert      # 规则的名称
      # 告警阈值计算规则为响应时间大于1000ms并持续10s的发送告警
      expr: (nginx_upstream_responseMsec &gt; 1000)
      for: 10s                      # 持续时间为10s
      labels:                       # 定义告警路由标签
            severity: critical
            service: nginx
        annotations:                # 告警信息
            summary: “Nginx响应大于1000ms”
            description: “Nginx {{ $labels.instance }}后端集群{{ $labels.upstream }} 中{{ $labels.backend }}的响应时间大于1000ms。当前值为：{{ $value }} ms”
EOF

# 重启Prometheus
docker restart prometheus
</pre>
  <hr class="calibre6"/>

  <p class="ziti4">·$labels是Metric行数据的labels内容。labels的内容可用对象数据类型方法引用。</p>

  <p class="ziti4">·$value是Metric行的value。</p>

  <p class="ziti4">·$labels是多条时，会自动遍历内容，每条记录生成一个annotations信息。</p>

  <p class="ziti3">（4）Alertmanager配置</p>
  <hr class="calibre6"/>
  <pre class="ziti5">cd /opt/data/apps

# 配置Alertmanager
cat&gt;prometheus/alertmanager/alertmanager.yml&lt;&lt;EOF
# 全局配置，配置smtp信息
global:
    resolve_timeout: 5m                             # 处理超时时间，默认为5min
    smtp_smarthost: 'smtp.exmail.qq.com:465'        # 邮箱smtp服务器代理，请替换自己的smtp
                                                        # 服务器地址
    smtp_from: 'monitor@nginxbar.org'               # 发送告警信息的邮箱地址，请替换自己的
                                                        # 邮箱地址
    smtp_auth_username: 'monitor@nginxbar.org'      # 邮箱账号，请替换自己的邮箱账号
    smtp_auth_password: '12345678'                  # 邮箱密码，请替换自己的邮箱密码
    smtp_require_tls: false

# 定义发送邮件的模板信息
templates:
    - 'template/*.tmpl'

# 定义发送告警邮件的路由信息，这个路由不仅可以接收所有的告警，还可以配置多个路由
route:
    group_by: ['alertname']                 # 告警信息分组依据，按照同类alertname
                                                        # 进行分组
    group_wait: 10s                                 # 最初等待10s发送告警通知
    group_interval: 60s                             # 在发送新告警前的等待时间
    repeat_interval: 1h                             # 发送重复告警的等待周期为1小时，避免产
                                                        # 生邮件风暴
    receiver: 'email'                       # 全局默认告警接收者的名称，与receivers
                                                        # 的name对应
    routes:
    - match:                                # 匹配labels存在如下标签的告警信息
            severity: critical
            service: nginx
        receiver: nginx_email                       #Nginx服务器警报接收者的名称

# 定义默认警报接收者信息
receivers:
    - name: 'email'                                 # 路由中对应的receiver名称
      email_configs:                                # 告警接收者邮箱配置
        - to: 'xiaodong.wang@freemud.com'           # 告警接收者的邮箱配置

    - name: 'nginx_email'                           # 路由中对应的receiver名称
      email_configs:                                # 告警接收者邮箱配置
        - to: 'xiaodong.wang@freemud.com'           # 告警接收者的邮箱配置

EOF

# 重启alertmanager
docker restart alertmanager
</pre>
  <hr class="calibre6"/>

  <p class="ziti3">Nginx监控项的阈值触发设置的告警规则时，Prometheus就会自动发送告警到目标邮箱。</p>
</body>
</html>
